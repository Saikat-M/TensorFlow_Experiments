{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Real-or-Fake-Face-Detector.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocp65XugTlIV",
        "colab_type": "text"
      },
      "source": [
        "I have used Google's Colab Notebook to implement this project. The working directory for coloab is the \"Content\" folder. We can see the available folder structure from clicking on the folder icon on the left.There we can upload files from our local system\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Oa_DLWYRNSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = 'real_and_fake_face_ReduceD.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('real_and_fake_face') #extracting the zip file and putting it in folder named 'real_and_fake_face' \n",
        "zip_ref.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBZ40D_NUC6G",
        "colab_type": "text"
      },
      "source": [
        "Let's see few file names from both the directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwhbNQcnT5AH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory with our training Real Face pictures\n",
        "train_Real_dir = os.path.join('real_and_fake_face/real_and_fake_face_ReduceD/Real Face')\n",
        "\n",
        "# Directory with our training Fake Face pictures\n",
        "train_Fake_dir = os.path.join('real_and_fake_face/real_and_fake_face_ReduceD/Fake Face')\n",
        "\n",
        "train_Real_names = os.listdir(train_Real_dir)\n",
        "print(train_Real_names[:5]) # First 5 file names of real images of training data has been printed.\n",
        "\n",
        "train_Fake_names = os.listdir(train_Fake_dir)\n",
        "print(train_Fake_names[:5]) # First 5 file names of fake images of training data has been printed."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mJ0q_RMNyU-",
        "colab_type": "text"
      },
      "source": [
        "We can get the total number of images in the respective directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvX82pWpN4D0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Total training real images:', len(os.listdir(train_Real_dir)))\n",
        "print('total training fake images:', len(os.listdir(train_Fake_dir)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEgfAVakOuI0",
        "colab_type": "text"
      },
      "source": [
        "Now let's see some of the pictures. But first,need configure the necessary libraries and parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr2i3qNdVHr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Parameters for our graph; we'll output images in a 3x3 configuration\n",
        "nrows = 3\n",
        "ncols = 3\n",
        "\n",
        "# Index for iterating over images\n",
        "pic_index = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33UNQ3CkVUkO",
        "colab_type": "text"
      },
      "source": [
        "Now, display a batch of 4 Real and 4 Fake pictures. You can rerun the cell to see a fresh batch each time:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R27gV__GVqfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up matplotlib fig, and size it to fit 3x3 pics\n",
        "fig = plt.gcf() # Here the gcf() function has been used to get the referece of the image \n",
        "fig.set_size_inches(ncols * 2, nrows * 2) # we can ste the size here. It is in inches.\n",
        "\n",
        "pic_index += 4 # Here we can set how many pictures we want to see at the output\n",
        "next_Real_pix = [os.path.join(train_Real_dir, fname) \n",
        "                for fname in train_Real_names[pic_index-4:pic_index]]\n",
        "next_Fake_pix = [os.path.join(train_Fake_dir, fname) \n",
        "                for fname in train_Fake_names[pic_index-4:pic_index]]\n",
        "\n",
        "for i, img_path in enumerate(next_Real_pix+next_Fake_pix):\n",
        "  # Set up subplot; subplot indices start at 1\n",
        "  sp = plt.subplot(nrows, ncols, i + 1)\n",
        "  sp.axis('Off') # Don't show axes (or gridlines)\n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr7tw6z-4sxk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<h2>Lets Build the model now</h2>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7AekoV75hqs",
        "colab_type": "text"
      },
      "source": [
        "Let's start by importing TensorFlow library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n02jnJzL5n1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJkcCE1S59kS",
        "colab_type": "text"
      },
      "source": [
        "<h3>Building the CNN</h3> \n",
        "Now we will be building the densely connected Convolutional Neural Network. TensorFlow helps us to resize the images as per our requirement during the operation. So we don't need to resize the actual image in our local file system. Hence gives us the iberty to experiemnt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIJTJxSE6WuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # We can further add or remove Convolution and pooling layer depending upon the complexicity and/or image sizes. \n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # Only 1 neuron in the output layer.As we are developing a Binary Classifier. The value for sigmoid activation function will be between 0-1\n",
        "    # Where 0 will be for Real images and 1 would be for Fake images.\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid') \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXNO6rfW6xM8",
        "colab_type": "text"
      },
      "source": [
        "<h3>'summary()' Method</h3>\n",
        "From the 'summary()' method we can see how the the image shape has been changed/reduced after the operation in every layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG0kL1i56pui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_tMulFt65VB",
        "colab_type": "text"
      },
      "source": [
        "<h3>Compiling the model</h3>\n",
        "As we are designing a Binary classifier,we have used 'binary_crossentropy' loss function. But we can use other loss functions to see how it impacts the model performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_lQJEFL6vRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyHyBkGE7Ed6",
        "colab_type": "text"
      },
      "source": [
        "<h3>Data Preprocessing</h3>\n",
        "\n",
        "1.'ImageDataGenerator' helps to read the data files from source and feed them to the network.\n",
        "\n",
        "2.'flow_from_directory' function of the *ImageDataGenerator* helps to label the data from the subdirectory name.\n",
        "\n",
        "3.So we don't need to label evry data by ourselves explicitly. We just point the directory which holds the subdirectories which intern holds the images of respective classes.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELnUvMA37BF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# All images will be rescaled by 1./255 to normalize the images before we feed it to the network.\n",
        "train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "# Flow training images in batches of 11 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'real_and_fake_face/real_and_fake_face_ReduceD/',  # This is the source directory for training images which holds the subdirectories\n",
        "        target_size=(300, 300),                            # All images will be resized to 300x300\n",
        "        batch_size=11,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAGxkrrk8DG8",
        "colab_type": "text"
      },
      "source": [
        "<h3>Callback</h3>\n",
        "This is the Callback function. While training it helps us to stop the training when required/desired accuracy is reached on the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq7eKPwX9FAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DESIRED_ACCURACY = 0.98\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self,epoch,logs={}):             #This function is called on each epoch end    \n",
        "        if (logs.get('accuracy')>DESIRED_ACCURACY):\n",
        "            self.model.stop_training=True\n",
        "            print('Reached 98% accuracy so cancelling training!')\n",
        "\n",
        "callbacks = myCallback()                              #Creating the object of 'myCallback()'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2O9lym49EdN",
        "colab_type": "text"
      },
      "source": [
        "<h3>Trainging the Model</h3>\n",
        "Now we have developed the model,it's time to train it. 'model.fit()' helps us to do so."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPh7BI9M8DlR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=3,  # No of steps required to use the entire training data in each epoch before it go to the next epoch\n",
        "      epochs=10,          # steps_per_epoch = total training sample/batch size\n",
        "      verbose=1,          # Different modes of showing progress bar. Verbosity mode 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
        "      callbacks=[callbacks])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQC9GtQP8tGb",
        "colab_type": "text"
      },
      "source": [
        "#For very high accuracy on training set, there can be a chance of *Overfitting*. So we need to carefully choose our no of epochs, no of training data etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a31DALR9-Jau",
        "colab_type": "text"
      },
      "source": [
        "<h3>Now Let's see how the model works on Unseen photos</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qtevb7E-bUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(300, 300))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        "  if classes[0]>0.5:\n",
        "    plt.imshow(img)\n",
        "    print(fn + \" is a REAL image\")\n",
        "  else:\n",
        "    plt.imshow(img)\n",
        "    print(fn + \" is a FAKE image\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}